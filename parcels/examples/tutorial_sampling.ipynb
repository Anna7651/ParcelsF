{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field sampling tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The particle trajectories allow us to study fields like temperature, plastic concentration or chlorophyll from a Lagrangian perspective. \n",
    "\n",
    "In this tutorial we will go through how particles can sample `Fields`, using temperature as an example. Along the way we will get to know the parcels class `Variable` (see [here](https://oceanparcels.org/gh-pages/html/#parcels.particle.Variable) for the documentation) and some of its methods. We import the `Variable` class as well as the standard modules needed to set up a simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules needed for the Parcels simulation\n",
    "from parcels import Variable, FieldSet, ParticleSet, JITParticle, AdvectionRK4\n",
    "import numpy as np\n",
    "from datetime import timedelta as delta\n",
    "\n",
    "# To open and look at the temperature data\n",
    "import xarray as xr \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to study the environmental temperature for plankton drifting around a peninsula. We have a dataset with surface ocean velocities and the corresponding sea surface temperature stored in netcdf files in the folder `\"Peninsula_data\"`. Besides the velocity fields, we load the temperature field using `extra_fields={'T': 'T'}`. The particles are released on the left hand side of the domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "FieldSet files not found: Peninsula_data/peninsulaT.nc",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e05a9199ca66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Velocity and temperature fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfieldset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFieldSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_parcels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Peninsula_data/peninsula\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra_fields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'T'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'T'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_time_extrapolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Particle locations and initial time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m  \u001b[1;31m# number of particles to be released\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\documents\\github\\parcels\\parcels\\fieldset.py\u001b[0m in \u001b[0;36mfrom_parcels\u001b[1;34m(cls, basename, uvar, vvar, indices, extra_fields, allow_time_extrapolation, time_periodic, deferred_load, field_chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    803\u001b[0m                                \u001b[0mdimensions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_time_extrapolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_time_extrapolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m                                \u001b[0mtime_periodic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_periodic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeferred_load\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeferred_load\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                                field_chunksize=field_chunksize, **kwargs)\n\u001b[0m\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\documents\\github\\parcels\\parcels\\fieldset.py\u001b[0m in \u001b[0;36mfrom_netcdf\u001b[1;34m(cls, filenames, variables, dimensions, indices, fieldtype, mesh, timestamps, allow_time_extrapolation, time_periodic, deferred_load, field_chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    374\u001b[0m             \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                 \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_wildcards\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gebruiker\\documents\\github\\parcels\\parcels\\fieldset.py\u001b[0m in \u001b[0;36mparse_wildcards\u001b[1;34m(cls, paths, filenames, var)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0mnotfound_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FieldSet files not found: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotfound_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: FieldSet files not found: Peninsula_data/peninsulaT.nc"
     ]
    }
   ],
   "source": [
    "# Velocity and temperature fields\n",
    "fieldset = FieldSet.from_parcels(\"Peninsula_data/peninsula\", extra_fields={'T': 'T'}, allow_time_extrapolation=True)\n",
    "\n",
    "# Particle locations and initial time\n",
    "npart = 10  # number of particles to be released\n",
    "lon = 3e3 * np.ones(npart)\n",
    "lat = np.linspace(3e3 , 45e3, npart, dtype=np.float32)\n",
    "time = np.arange(0, npart) * delta(hours=2).total_seconds()  # release each particle two hours later\n",
    "\n",
    "# Plot temperature field and initial particle locations\n",
    "T_data = xr.open_dataset(\"Peninsula_data/peninsulaT.nc\")\n",
    "plt.figure()\n",
    "ax = plt.axes()\n",
    "T_contour = ax.contourf(T_data.x.values, T_data.y.values, T_data.T.values[0,0], cmap=plt.cm.inferno)\n",
    "ax.scatter(lon, lat, c='w')\n",
    "plt.colorbar(T_contour, label='T [$^{\\circ} C$]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sample the temperature field, we need to create a new class of particles where temperature is a `Variable`. As an argument for the `Variable` class, we need to provide the initial values for the particles. The easiest option is to access `fieldset.T`, but this option has some drawbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleParticle(JITParticle):         # Define a new particle class\n",
    "    temperature = Variable('temperature', initial=fieldset.T)  # Variable 'temperature' initialised by sampling the temperature\n",
    "\n",
    "pset = ParticleSet(fieldset=fieldset, pclass=SampleParticle, lon=lon, lat=lat, time=time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `fieldset.T` leads to the `WARNING` displayed above because `Variable` accesses the fieldset in the slower SciPy mode. Another problem can occur when using the repeatdt argument instead of time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "repeatdt = delta(hours=3)\n",
    "\n",
    "pset = ParticleSet(fieldset=fieldset, pclass=SampleParticle, lon=lon, lat=lat, repeatdt=repeatdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the initial time is not defined, the `Variable` class does not know at what time to access the temperature field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution to this initialisation problem is to leave the initial value zero and sample the initial condition in JIT mode with the sampling Kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleParticleInitZero(JITParticle):         # Define a new particle class\n",
    "    temperature = Variable('temperature', initial=0)  # Variable 'temperature' initially zero\n",
    "\n",
    "pset = ParticleSet(fieldset=fieldset, pclass=SampleParticleInitZero, lon=lon, lat=lat, time=time)\n",
    "\n",
    "def SampleT(particle, fieldset, time):\n",
    "         particle.temperature = fieldset.T[time, particle.depth, particle.lat, particle.lon]\n",
    "sample_kernel = pset.Kernel(SampleT)    # Casting the SampleT function to a kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sample the initial values we can execute the Sample kernel over the entire particleset with dt = 0 so that time does not increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset.execute(sample_kernel, dt=0) # by only executing the sample kernel we record the initial temperature of the particles\n",
    "\n",
    "output_file = pset.ParticleFile(name=\"InitZero.nc\", outputdt=delta(hours=1))\n",
    "pset.execute(AdvectionRK4 + sample_kernel, runtime=delta(hours=30), dt=delta(minutes=5),\n",
    "             output_file=output_file)\n",
    "output_file.export()  # export the trajectory data to a netcdf file\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The particle dataset now contains the particle trajectories and the corresponding environmental temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Particle_data = xr.open_dataset(\"InitZero.nc\")\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylim(1000, 49000)\n",
    "ax.set_xlim(1000, 99000)\n",
    "ax.plot(Particle_data.lon.transpose(), Particle_data.lat.transpose(), c='k', zorder=1)\n",
    "T_scatter = ax.scatter(Particle_data.lon, Particle_data.lat, c=Particle_data.temperature, \n",
    "                       cmap=plt.cm.inferno, norm=mpl.colors.Normalize(vmin=0., vmax=20.), \n",
    "                       edgecolor='k', zorder=2)\n",
    "plt.colorbar(T_scatter, label='T [$^{\\circ} C$]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling initial values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some simulations only the particles initial value within the field is of interest: the variable does not need to be known along the entire trajectory. To reduce computing we can specify the `to_write` argument to the temperature `Variable`. This argument can have three values: `True`, `False` or `'once'`. It determines whether to write the `Variable` to the output file. If we want to know only the initial value, we can enter `'once'` and only the first value will be written to the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleParticleOnce(JITParticle):         # Define a new particle class\n",
    "    temperature = Variable('temperature', initial=0, to_write='once')  # Variable 'temperature'\n",
    "    \n",
    "pset = ParticleSet(fieldset=fieldset, pclass=SampleParticleOnce, lon=lon, lat=lat, time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset.execute(sample_kernel, dt=0) # by only executing the sample kernel we record the initial temperature of the particles\n",
    "\n",
    "output_file = pset.ParticleFile(name=\"WriteOnce.nc\", outputdt=delta(hours=1))\n",
    "pset.execute(AdvectionRK4, runtime=delta(hours=24), dt=delta(minutes=5),\n",
    "             output_file=output_file)\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the particles are released at the same x-position and the temperature field is invariant in the y-direction, all particles have an initial temperature of 0.4$^\\circ$C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Particle_data = xr.open_dataset(\"WriteOnce.nc\")\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylim(1000, 49000)\n",
    "ax.set_xlim(1000, 99000)\n",
    "ax.plot(Particle_data.lon.transpose(), Particle_data.lat.transpose(), c='k', zorder=1)\n",
    "T_scatter = ax.scatter(Particle_data.lon, Particle_data.lat, \n",
    "                       c=np.tile(Particle_data.temperature, (Particle_data.lon.shape[1], 1)).T,\n",
    "                       cmap=plt.cm.inferno, norm=mpl.colors.Normalize(vmin=0., vmax=1.), \n",
    "                       edgecolor='k', zorder=2)\n",
    "plt.colorbar(T_scatter, label='Initial T [$^{\\circ} C$]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling with repeatdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some experiments require large sets of particles to be released repeatedly on the same locations. The parcels [`particleset`](https://oceanparcels.org/gh-pages/html/#module-parcels.particleset) has the option `repeatdt` for this, but when you want to sample the initial values this introduces some problems as we have seen before. To get more control over the repeated release of particles, you can manually write the for-loop which `repeatdt` basically exectues under the hood using the function `particleset.add()`.\n",
    "\n",
    "In the loop, we want to initialise new particles and sample their initial temperature. Then we want to advect all particles until the next release. Parcels can only write particles to the output file once for each moment in time. If we want to write both the initialised particles with the sampled temperature and the older particles that have already been advected, we have to make sure both sets of particles find themselves at the same moment in time. In this loop that moment is in between initialising the particles and advecting them. We do not specify the outputdt argument for the `output_file` and instead write the data with `output_file.write(pset,time)`. Because the advection takes place after the writing, we need to add one writing instance after the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.zeros(npart)                    # release all particles of the set at the same time\n",
    "repeatdt = delta(hours=6).total_seconds() # release each set of particles seven hours later\n",
    "repeatx = 4                               # amount of times to release the particleset\n",
    "# outputdt = delta(hours=1).total_seconds() # Figure out if and how we want to increase the outputdt wrt the repeatdt\n",
    "\n",
    "pset = ParticleSet(fieldset=fieldset, pclass=SampleParticleInitZero, lon=[], lat=[], time=[]) # Using SampleParticleInitZero\n",
    "output_file = pset.ParticleFile(name=\"RepeatLoop.nc\") # Do not specify the outputdt yet, so we can manually write the output\n",
    "\n",
    "for i in range(repeatx):\n",
    "    pset_init = ParticleSet(fieldset=fieldset, pclass=SampleParticleInitZero, lon=lon, lat=lat, time=time) # the set of particles to be released at the current timestep\n",
    "    pset_init.execute(sample_kernel, dt=0) # by only executing the sample kernel we record the initial temperature of the particles\n",
    "    \n",
    "    pset.add(pset_init)                    # add the newly released particles to the total particleset\n",
    "    output_file.write(pset,time[0])        # write the initialised particles and the advected particles\n",
    "\n",
    "    pset.execute(AdvectionRK4+sample_kernel, runtime=repeatdt, dt=delta(minutes=5))\n",
    "    \n",
    "    print('Length of pset: %d' % len(pset))\n",
    "    \n",
    "    time += repeatdt #\n",
    "\n",
    "output_file.write(pset,time[0])\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each iteration of the loop, spanning six hours, we have added ten particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Particle_data = xr.open_dataset(\"RepeatLoop.nc\")\n",
    "print(Particle_data.time[:,0].values/3600000000000) # The initial hour at which each particle is released"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the initial temperatures were sampled correctly for all particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Particle_data.temperature[:,0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And see if the sampling of the temperature field is done correctly along the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Release0 = Particle_data.where(Particle_data.time[:,0]==np.timedelta64(0, 's')) # the particles released at t = 0\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylim(1000, 49000)\n",
    "ax.set_xlim(1000, 99000)\n",
    "ax.plot(Release0.lon.transpose(), Release0.lat.transpose(), c='k', zorder=1)\n",
    "T_scatter = ax.scatter(Release0.lon, Release0.lat, c=Release0.temperature, \n",
    "                       cmap=plt.cm.inferno, norm=mpl.colors.Normalize(vmin=0., vmax=20.), \n",
    "                       edgecolor='k', zorder=2)\n",
    "plt.colorbar(T_scatter, label='T [$^{\\circ} C$]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Metagegevens bewerken",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
