{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2d8b054",
   "metadata": {},
   "source": [
    "# Combining large ocean-parcels datasets and choosing an optimal chunking. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5792d0",
   "metadata": {},
   "source": [
    "You might imagine that if you followed the instructions [on the making of parallel runs](https://github.com/OceanParcels/parcels/blob/dump_to_zarr/parcels/examples/documentation_MPI.ipynb) and the loading of the resulting dataset, you could just use the `dataset.to_zarr()` function to save the data to a single zarr datastore. This is true for small enough datasets -- but for a number of reasons, including the non-contiguous trajectory coordinate, if you try this with datasets whose size is larger than a 1/3 or so of the memory of your computer, you will find that it takes a long time, then fails as it exhausts the memory of your computer. \n",
    "\n",
    "This may be fixed in xarray or zarr in the future, but for now, we can work around this problem by saving the output in steps. \n",
    "\n",
    "At the same time, we can change the datatype of the output and modify the chunking of the dataset. Both of these can improve both performance and the size of the data on the disk. However, some care is required to do this, and this will be described in more detail below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4010c8d0",
   "metadata": {},
   "source": [
    "## Why are we doing this? And what chunk sizes should we choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb22d5",
   "metadata": {},
   "source": [
    "If you are running a relatively small case (perhaps 1/10 the size of the memory of your machine), nearly anything you do will work. However, as your problems get larger, it can help to write the data into a single zarr datastore, and to chunk that store appropriately. \n",
    "\n",
    "To illustrate this, here is the time it takes to retrieve all the results (with `ds['variableName'].values`) of some common data structures with different chunk sizes. (What is a chunk size? More on that below). The data in this example has 39 million trajectories starting over 120 times, and there are 250 observations, resulting in a directory size of 88Gb in double precision and 39 in single. In this table, \"trajectory:5e4, obs:10\" indicates that each chunk extends over 50,000 trajectories and 10 obs. The chunking in the original data is roughly a few thousand observations and 10 obs. \n",
    "\n",
    "|File type|open [s]|read 1 obs, all traj [s]|read 23 obs, all traj [s]|read 8000 contigous traj, all obs [s]|read traj that start at a given time, all obs [s]|\n",
    "|---|---|---|---|---|---|\n",
    "|Straigth from parcels|2.9|8.4|59.9|1.5|17.4|\n",
    "|trajectory:5e4, obs:10|0.48|2.5|19.5|0.4|10.33|\n",
    "|trajectory:5e4, obs:100|0.55|20.5|13.8|0.5|3.88|\n",
    "|trajectory:5e5, obs:10|0.54|2.2|16.3|0.85|18.5|\n",
    "|trajectory:5e5, obs:100|0.46|19.9|40.0|0.62|49.36|\n",
    "\n",
    "\n",
    "You can see several things in this. It is always quicker to open a single file, and for all data access patterns, there is are chunksizes that are more efficient than the default output. Why is this?\n",
    "\n",
    "The chunksize determines how data is stored on disk. For the default Zarr datastore, each chunk of data is stored as a single compressed file. In netCDF, chunking is similar except that the compressed data is stored within a single file. In either case, if you must access any data from within a chunk, you must read the entire chunk from disk. \n",
    "\n",
    "So when we access one obs dimension and many trajectories, the chunking scheme that is elongated in the trajectory direction is fastest. When we get all the observation for a scattered set of trajectories, the chunking that is elongated in observations is the best. In general, the product of the two chunksizes (the number of data points in a chunk) should be hundreds of thousands to 10s of millions.  A suboptimal chunking scheme is usually not tragic, but if you know how you will most often access the data, you can save considerable time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d3385",
   "metadata": {},
   "source": [
    "## How to save the output of an MPI ocean parcels run to a single zarr dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5001615",
   "metadata": {},
   "source": [
    "First, we need to import the necessary modules, specify the directory `inputDir` which contains the output of the parcels run (the directory that has proc01, proc02 and so forth), the location of the ouput zarr file `outputDir` and a dictionary giving the chunk size for the `trajectory` and `obs` coordinates, `chunksize`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2622a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pylab import *\n",
    "from numpy import *\n",
    "from glob import glob\n",
    "from os import path\n",
    "import time\n",
    "\n",
    "#first specify the directory in which the MPI code wrote its output\n",
    "inputDir=('dataPathsTemp/'+\n",
    "         'theAmericas_wholeGlobe_range100km_depthFrom_1m_to_500m_habitatTree_months01_to_02_fixed_1m/'+\n",
    "         '2008/tracks.zarr')\n",
    "\n",
    "\n",
    "#specify chunksize and where the output zarr file should go; also set chunksize of output file\n",
    "chunksize={'trajectory':5*int(1e4),'obs':10}; \n",
    "outputDir='/home/pringle/jnkData/singleFile_5e4_X_10_example.zarr'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33383cbe",
   "metadata": {},
   "source": [
    "Now for large datasets, this code can take a while to run; for 36 million trajectories and 250 observations, it can take an hour and a half. I prefer not to accidently destroy data that takes more than an hour to create, so I put in a safety check and only let the code run if the output directory does not exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a1414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not overwrite existing data sets\n",
    "if path.exists(outputDir):\n",
    "    print('the ouput path',outputDir,'exists')\n",
    "    print('please delete if you want to replace it')\n",
    "    assert False,'stopping execution'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8818397",
   "metadata": {},
   "source": [
    "It will often be useful to change the [`dtype`](https://numpy.org/doc/stable/reference/generated/numpy.dtype.html) of the output data. Doing so can save a great deal of disk space. For example, the input data for this example is 88Gb in size, but by changing lat, lon and z to single precision, I can make the file about half as big. \n",
    "\n",
    "This comes at the cost of some accuracy. Float64 has 14 digits of accuracy, float32 has 7. For latitude and longitude, going from float64 to float32 increases the error by the circumfrence of the Earth devided 1e7, or about 1m. This is good enough for what I am doing. However, a year of time has about 3.15e7 seconds, and we often want to know within a second when a particle is released (to avoid floating point issues when picking out particles that start at a specific time). So the 3.15e7/1e7 error (a few seconds) in the time coordinate could cause problems. So I don't want to reduce the precision of time. \n",
    "\n",
    "To change precision, put an entry into the dictionary `varType` whose key is the name of the variable, and whose value is the type you wish the variable to be cast to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca2bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "varType={\n",
    "         'lat':dtype('float32'),\n",
    "         'lon':dtype('float32'),\n",
    "          'time':dtype('datetime64'),\n",
    "         'z':dtype('float32'),\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e9ba7",
   "metadata": {},
   "source": [
    "Now we need to read in the data as discussed in the section on making an MPI run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7dd9f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening data from multiple process files\n",
      "   done opening in  2.19\n"
     ]
    }
   ],
   "source": [
    "print('opening data from multiple process files')\n",
    "tic=time.time()\n",
    "files = glob(path.join(inputDir, \"proc*\")); \n",
    "dataIn = xr.concat([xr.open_zarr(f) for f in files], dim='trajectory', \n",
    "                     compat='no_conflicts', coords='minimal') \n",
    "print('   done opening in %5.2f'%(time.time()-tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93a60ff",
   "metadata": {},
   "source": [
    "Now we can take advantage of the `.astype` operator to change the type of the variables. This is a lazy operator, and it will only be applied to the data when the data values are requested below, when the data is written to a new zarr store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6819cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in varType.keys():\n",
    "    dataIn[v]=dataIn[v].astype(varType[v])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8410589",
   "metadata": {},
   "source": [
    "The dataset is then rechunked to our desired shape. This does not actually do anything right now, but will when the data is written below. Before doing this, it is useful to remove the per-variable chunking metadata, because of inconsistencies which arrise due to (I think) each MPI process output having a different chunking. This is explained in more detail in https://github.com/dcs4cop/xcube/issues/347  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a56c3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re-chunking\n",
      "   done in 3.4046807289123535\n"
     ]
    }
   ],
   "source": [
    "print('re-chunking')\n",
    "tic=time.time()\n",
    "for v in dataIn.variables:\n",
    "    if 'chunks' in dataIn[v].encoding:\n",
    "        del dataIn[v].encoding['chunks']\n",
    "dataIn=dataIn.chunk(chunksize)\n",
    "print('   done in',time.time()-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f59018b",
   "metadata": {},
   "source": [
    "The dataset `dataIn` is now ready to be written back out in stages. But how big is each segment that will be written out? I have found that writing out about 650 million points per variable is easy on a laptop with 16Gb of memory.  Larger sizes might be more efficient, but one does run into the law of diminishing returns fairly quickly. The number of points to write out is called `nPointsWrite` and it is integer devided by the `obs` dimension to get the number of rows to write out, `writeChunkLen`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de5415ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nPointsWrite=int(5e6)*130\n",
    "writeChunkLen=nPointsWrite//dataIn.dims['obs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b210d2c",
   "metadata": {},
   "source": [
    "Now, at some point in the future, one could imagine making this code parallel; to make that easier, make sure that writeChunkLen is an even multiple of the trajectory chunk size, and also make sure it is at least one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecda3883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   writing 2600000 trajectory's at a time\n"
     ]
    }
   ],
   "source": [
    "writeChunkLen=(writeChunkLen//chunksize['trajectory'])*chunksize['trajectory']\n",
    "writeChunkLen=max(1,writeChunkLen) #must be at least 1!\n",
    "print(\"   writing %d trajectory's at a time\"%(writeChunkLen,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bd78bc",
   "metadata": {},
   "source": [
    "Now we want to make a list of the indices that are to be written out, `chunkList`, so it goes from 0 to the total size of the trajectory dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c993c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make list of indices to write out, inclusive of end of the trajectory dimension\n",
    "chunkList=list(range(0,dataIn.dims['trajectory'],writeChunkLen))\n",
    "if chunkList[-1]!=dataIn.dims['trajectory']:\n",
    "    chunkList.append(dataIn.dims['trajectory'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d6ace4",
   "metadata": {},
   "source": [
    "Now iterate through the indices in chunkList, and write out each bit. The following code is a bit chatty, but as the code can take a while to run, I find it reassuring to know it is doing something. If one errs in using xarray, it can take an excessive amount of time to do things, so it is worth keeping an eye on things. After you start the code below running, go teach a class or revise a manuscript. It can take a while. On my test 88Gb file, it takes about an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c14e2d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to write to /home/pringle/jnkData/singleFile_5e4_X_10_example.zarr\n",
      "   getting chunk 0\n",
      "   starting to write\n",
      "   done with chunk 0 of 15 from 0 to 2600000 in 484.8957693576813\n",
      "   getting chunk 1\n",
      "   starting to write\n",
      "   done with chunk 1 of 15 from 2600000 to 5200000 in 490.55356001853943\n",
      "   getting chunk 2\n",
      "   starting to write\n",
      "   done with chunk 2 of 15 from 5200000 to 7800000 in 550.8107087612152\n",
      "   getting chunk 3\n",
      "   starting to write\n",
      "   done with chunk 3 of 15 from 7800000 to 10400000 in 484.8843400478363\n",
      "   getting chunk 4\n",
      "   starting to write\n",
      "   done with chunk 4 of 15 from 10400000 to 13000000 in 440.20081901550293\n",
      "   getting chunk 5\n",
      "   starting to write\n",
      "   done with chunk 5 of 15 from 13000000 to 15600000 in 344.02604961395264\n",
      "   getting chunk 6\n",
      "   starting to write\n",
      "   done with chunk 6 of 15 from 15600000 to 18200000 in 337.93852186203003\n",
      "   getting chunk 7\n",
      "   starting to write\n",
      "   done with chunk 7 of 15 from 18200000 to 20800000 in 455.27793192863464\n",
      "   getting chunk 8\n",
      "   starting to write\n",
      "   done with chunk 8 of 15 from 20800000 to 23400000 in 405.1483941078186\n",
      "   getting chunk 9\n",
      "   starting to write\n",
      "   done with chunk 9 of 15 from 23400000 to 26000000 in 310.73776030540466\n",
      "   getting chunk 10\n",
      "   starting to write\n",
      "   done with chunk 10 of 15 from 26000000 to 28600000 in 286.34414768218994\n",
      "   getting chunk 11\n",
      "   starting to write\n",
      "   done with chunk 11 of 15 from 28600000 to 31200000 in 247.74302196502686\n",
      "   getting chunk 12\n",
      "   starting to write\n",
      "   done with chunk 12 of 15 from 31200000 to 33800000 in 165.62516450881958\n",
      "   getting chunk 13\n",
      "   starting to write\n",
      "   done with chunk 13 of 15 from 33800000 to 36400000 in 155.9800374507904\n",
      "   getting chunk 14\n",
      "   starting to write\n",
      "   done with chunk 14 of 15 from 36400000 to 39000000 in 204.0485861301422\n",
      "   getting chunk 15\n",
      "   starting to write\n",
      "   done with chunk 15 of 15 from 39000000 to 39692941 in 43.03104019165039\n",
      "Done writing in 5425.2\n"
     ]
    }
   ],
   "source": [
    "#write out the chunks\n",
    "print('starting to write to',outputDir)\n",
    "for nChunk in range(len(chunkList)-1):\n",
    "    innerTic=time.time()\n",
    "    print('   getting chunk',nChunk)\n",
    "    newds=dataIn.isel(trajectory=np.arange(chunkList[nChunk],chunkList[nChunk+1])) #do not sort by trajectory\n",
    "    print('   starting to write')\n",
    "    if nChunk==0:\n",
    "        newds.to_zarr(outputDir,mode='w')\n",
    "    else:\n",
    "        newds.to_zarr(outputDir,append_dim='trajectory')\n",
    "    print('   done with chunk %d of %d from'%(nChunk,len(chunkList)-2),\n",
    "          chunkList[nChunk],'to',chunkList[nChunk+1],'in',time.time()-innerTic)\n",
    "\n",
    "print('Done writing in %5.1f'%(time.time()-tic,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9080025f",
   "metadata": {},
   "source": [
    "We can now load the zarr data set we have created, and see what is in it, compared to what was in the input dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3157592c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data\n",
      " <xarray.Dataset>\n",
      "Dimensions:     (trajectory: 39692941, obs: 250)\n",
      "Coordinates:\n",
      "  * obs         (obs) int32 0 1 2 3 4 5 6 7 ... 242 243 244 245 246 247 248 249\n",
      "  * trajectory  (trajectory) int64 16 23 68 165 ... 39692792 39692889 39692920\n",
      "Data variables:\n",
      "    age         (trajectory, obs) float32 dask.array<chunksize=(3938, 10), meta=np.ndarray>\n",
      "    lat         (trajectory, obs) float64 dask.array<chunksize=(3938, 10), meta=np.ndarray>\n",
      "    lon         (trajectory, obs) float64 dask.array<chunksize=(3938, 10), meta=np.ndarray>\n",
      "    time        (trajectory, obs) datetime64[ns] dask.array<chunksize=(3938, 10), meta=np.ndarray>\n",
      "    z           (trajectory, obs) float64 dask.array<chunksize=(3938, 10), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:            CF-1.6/CF-1.7\n",
      "    feature_type:           trajectory\n",
      "    ncei_template_version:  NCEI_NetCDF_Trajectory_Template_v2.0\n",
      "    parcels_mesh:           spherical\n",
      "    parcels_version:        2.3.2.dev137 \n",
      "\n",
      "The new dataSet\n",
      " <xarray.Dataset>\n",
      "Dimensions:     (trajectory: 39692941, obs: 250)\n",
      "Coordinates:\n",
      "  * obs         (obs) int32 0 1 2 3 4 5 6 7 ... 242 243 244 245 246 247 248 249\n",
      "  * trajectory  (trajectory) int64 16 23 68 165 ... 39692792 39692889 39692920\n",
      "Data variables:\n",
      "    age         (trajectory, obs) float32 dask.array<chunksize=(50000, 10), meta=np.ndarray>\n",
      "    lat         (trajectory, obs) float32 dask.array<chunksize=(50000, 10), meta=np.ndarray>\n",
      "    lon         (trajectory, obs) float32 dask.array<chunksize=(50000, 10), meta=np.ndarray>\n",
      "    time        (trajectory, obs) datetime64[ns] dask.array<chunksize=(40625, 8), meta=np.ndarray>\n",
      "    z           (trajectory, obs) float32 dask.array<chunksize=(50000, 10), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:            CF-1.6/CF-1.7\n",
      "    feature_type:           trajectory\n",
      "    ncei_template_version:  NCEI_NetCDF_Trajectory_Template_v2.0\n",
      "    parcels_mesh:           spherical\n",
      "    parcels_version:        2.3.2.dev137\n"
     ]
    }
   ],
   "source": [
    "dataOriginal=dataIn = xr.concat([xr.open_zarr(f) for f in files], dim='trajectory', \n",
    "                     compat='no_conflicts', coords='minimal') \n",
    "dataProcessed=xr.open_zarr(outputDir)\n",
    "print('The original data\\n',dataOriginal,'\\n\\nThe new dataSet\\n',dataProcessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c678b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
